"""
Chronos-T5ï¼ˆé¢„è®­ç»ƒæ—¶é—´åºåˆ—å¤§æ¨¡å‹ï¼‰

é€‚ç”¨ï¼šé›¶/å°‘æ ·æœ¬ã€å¿«é€Ÿè·å¾—å¼ºåŸºçº¿ï¼›æ”¯æŒæ¦‚ç‡é¢„æµ‹ä¸å¤šé¢‘ç‡
ä½¿ç”¨è¦ç‚¹ï¼šæŒ‡å®šé¢‘ç‡ä¸º 10 åˆ†é’Ÿã€é¢„æµ‹æ­¥æ•° 1008ï¼›å¯å¾®è°ƒä»¥è´´åˆæœ¬æ•°æ®åˆ†å¸ƒ
ä¼˜ç‚¹ï¼šå³ç”¨å³å‡†ã€æ³›åŒ–å¼º
ç¼ºç‚¹ï¼šæ¨¡å‹è¾ƒå¤§ï¼Œæ¨ç†èµ„æºå ç”¨é«˜
"""

import numpy as np
import pandas as pd
import torch
from typing import Optional, List, Dict
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import warnings
from tqdm import tqdm
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

warnings.filterwarnings('ignore')

# é…ç½®ä¸­æ–‡å­—ä½“
from utils.plot_config import setup_chinese_font, apply_plot_style
setup_chinese_font()

try:
    from chronos import ChronosPipeline
    CHRONOS_AVAILABLE = True
except ImportError:
    CHRONOS_AVAILABLE = False
    print("è­¦å‘Š: Chronosåº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install git+https://github.com/amazon-science/chronos-forecasting.git")


class ChronosForecaster:
    """
    Chronos-T5é¢„è®­ç»ƒæ¨¡å‹é¢„æµ‹å™¨
    """
    def __init__(self,
                 model_name: str = "amazon/chronos-t5-small",
                 prediction_length: int = 1008,
                 num_samples: int = 20,
                 temperature: float = 1.0,
                 top_k: Optional[int] = 50,
                 top_p: Optional[float] = 1.0,
                 device: str = 'auto'):
        """
        Parameters:
        -----------
        model_name : str
            æ¨¡å‹åç§°ï¼Œå¯é€‰:
            - amazon/chronos-t5-tiny (8Må‚æ•°)
            - amazon/chronos-t5-mini (20Må‚æ•°)
            - amazon/chronos-t5-small (46Må‚æ•°)
            - amazon/chronos-t5-base (200Må‚æ•°)
            - amazon/chronos-t5-large (710Må‚æ•°)
        prediction_length : int
            é¢„æµ‹é•¿åº¦
        num_samples : int
            é‡‡æ ·æ•°é‡ï¼ˆç”¨äºæ¦‚ç‡é¢„æµ‹ï¼‰
        temperature : float
            é‡‡æ ·æ¸©åº¦
        top_k : int
            Top-Ké‡‡æ ·
        top_p : float
            Top-Pé‡‡æ ·
        device : str
            è®¾å¤‡ï¼Œ'auto'è‡ªåŠ¨æ£€æµ‹GPUï¼Œ'cuda'å¼ºåˆ¶GPUï¼Œ'cpu'å¼ºåˆ¶CPU
        """
        if not CHRONOS_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£…Chronosåº“")

        self.model_name = model_name
        self.prediction_length = prediction_length
        self.num_samples = num_samples
        self.temperature = temperature
        self.top_k = top_k
        self.top_p = top_p

        # æ£€æµ‹GPUå…¼å®¹æ€§
        use_gpu = False
        if device == 'auto' or device == 'cuda':
            if torch.cuda.is_available():
                try:
                    # æµ‹è¯•CUDAæ˜¯å¦çœŸæ­£å¯ç”¨
                    test_tensor = torch.zeros(1, device='cuda')
                    _ = test_tensor + 1
                    use_gpu = True
                    self.device = 'cuda'
                    print(f"[OK] æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
                    print(f"   GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
                except RuntimeError as e:
                    if 'no kernel image is available' in str(e):
                        print(f"[INFO] GPUæ£€æµ‹åˆ°ä½†ä¸å…¼å®¹ (RTX 5060 Tiéœ€è¦æ›´æ–°çš„PyTorch)")
                        print("   è‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
                        self.device = 'cpu'
                    else:
                        raise
            else:
                self.device = 'cpu'
                print("[INFO] æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUï¼ˆæ¨ç†é€Ÿåº¦ä¼šè¾ƒæ…¢ï¼‰")
        else:
            self.device = device
            if device == 'cuda':
                print(f"[OK] ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")

        print(f"\nåŠ è½½ Chronos æ¨¡å‹: {model_name}")
        print(f"è®¾å¤‡: {self.device.upper()}")
        if self.device == 'cuda':
            print("ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨ï¼Œä½¿ç”¨bfloat16ç²¾åº¦")

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.pipeline = ChronosPipeline.from_pretrained(
            model_name,
            device_map=self.device,
            dtype=torch.bfloat16 if self.device == 'cuda' else torch.float32,
        )

        print("æ¨¡å‹åŠ è½½å®Œæˆ!")

    def predict_single_series(self, context: np.ndarray,
                             prediction_length: Optional[int] = None) -> Dict[str, np.ndarray]:
        """
        å¯¹å•ä¸ªæ—¶é—´åºåˆ—è¿›è¡Œé¢„æµ‹

        Parameters:
        -----------
        context : np.ndarray
            å†å²æ•°æ®
        prediction_length : int, optional
            é¢„æµ‹é•¿åº¦

        Returns:
        --------
        result : dict
            åŒ…å« 'mean', 'median', 'quantiles' çš„é¢„æµ‹ç»“æœ
        """
        if prediction_length is None:
            prediction_length = self.prediction_length

        # è½¬æ¢ä¸ºtorchå¼ é‡
        context_tensor = torch.tensor(context, dtype=torch.float32)

        # é¢„æµ‹
        with torch.no_grad():
            forecast = self.pipeline.predict(
                inputs=context_tensor,
                prediction_length=prediction_length,
                num_samples=self.num_samples,
                temperature=self.temperature,
                top_k=self.top_k,
                top_p=self.top_p
            )

        # è½¬æ¢ä¸ºnumpy
        forecast_samples = forecast.cpu().numpy()  # (num_samples, prediction_length)

        # è®¡ç®—ç»Ÿè®¡é‡
        result = {
            'mean': forecast_samples.mean(axis=0),
            'median': np.median(forecast_samples, axis=0),
            'std': forecast_samples.std(axis=0),
            'q10': np.percentile(forecast_samples, 10, axis=0),
            'q25': np.percentile(forecast_samples, 25, axis=0),
            'q75': np.percentile(forecast_samples, 75, axis=0),
            'q90': np.percentile(forecast_samples, 90, axis=0),
            'samples': forecast_samples
        }

        return result

    def predict(self, df: pd.DataFrame,
                time_col: str,
                value_cols: List[str],
                context_length: int = 2016,
                prediction_length: Optional[int] = None,
                use_median: bool = True) -> pd.DataFrame:
        """
        å¯¹å¤šä¸ªåŒºåŸŸè¿›è¡Œé¢„æµ‹

        Parameters:
        -----------
        df : pd.DataFrame
            åŒ…å«å†å²æ•°æ®çš„DataFrame
        time_col : str
            æ—¶é—´åˆ—
        value_cols : list
            åŒºåŸŸåˆ—
        context_length : int
            ä½¿ç”¨çš„å†å²æ•°æ®é•¿åº¦
        prediction_length : int, optional
            é¢„æµ‹é•¿åº¦
        use_median : bool
            æ˜¯å¦ä½¿ç”¨ä¸­ä½æ•°ï¼ˆå¦åˆ™ä½¿ç”¨å‡å€¼ï¼‰

        Returns:
        --------
        predictions_df : pd.DataFrame
            é¢„æµ‹ç»“æœ
        """
        if prediction_length is None:
            prediction_length = self.prediction_length

        print(f"\nå¼€å§‹é¢„æµ‹ {len(value_cols)} ä¸ªåŒºåŸŸï¼Œé¢„æµ‹æ­¥æ•°: {prediction_length}")
        print(f"ä½¿ç”¨ä¸Šä¸‹æ–‡é•¿åº¦: {context_length}")

        predictions = {}
        prediction_intervals = {}

        for region in tqdm(value_cols, desc="é¢„æµ‹è¿›åº¦"):
            # è·å–å†å²æ•°æ®
            context = df[region].values[-context_length:]

            # å¤„ç†ç¼ºå¤±å€¼
            if np.isnan(context).any():
                context = pd.Series(context).fillna(method='ffill').fillna(method='bfill').values

            # é¢„æµ‹
            try:
                result = self.predict_single_series(context, prediction_length)

                # é€‰æ‹©ä½¿ç”¨ä¸­ä½æ•°æˆ–å‡å€¼ï¼Œå¹¶ç¡®ä¿æ˜¯1ç»´æ•°ç»„
                if use_median:
                    pred = result['median']
                else:
                    pred = result['mean']

                # å¼ºåˆ¶å±•å¹³ä¸º1ç»´æ•°ç»„
                predictions[region] = np.array(pred).flatten()

                # ä¿å­˜ç½®ä¿¡åŒºé—´ï¼Œä¹Ÿç¡®ä¿æ˜¯1ç»´
                prediction_intervals[region] = {
                    'lower': np.array(result['q10']).flatten(),
                    'upper': np.array(result['q90']).flatten()
                }

            except Exception as e:
                print(f"\nåŒºåŸŸ {region} é¢„æµ‹å¤±è´¥: {e}")
                predictions[region] = np.full(prediction_length, np.nan)
                prediction_intervals[region] = {
                    'lower': np.full(prediction_length, np.nan),
                    'upper': np.full(prediction_length, np.nan)
                }

        # æ£€æŸ¥æ‰€æœ‰é¢„æµ‹æ•°ç»„çš„ç»´åº¦å’Œé•¿åº¦
        for region, arr in predictions.items():
            # ç¡®ä¿æ˜¯1ç»´æ•°ç»„
            predictions[region] = np.array(arr).flatten()
            # ç¡®ä¿ç½®ä¿¡åŒºé—´ä¹Ÿæ˜¯1ç»´
            if region in prediction_intervals:
                prediction_intervals[region]['lower'] = np.array(prediction_intervals[region]['lower']).flatten()
                prediction_intervals[region]['upper'] = np.array(prediction_intervals[region]['upper']).flatten()

        lengths = {region: len(arr) for region, arr in predictions.items()}
        if len(set(lengths.values())) > 1:
            print(f"\n[WARN] è­¦å‘Š: é¢„æµ‹ç»“æœé•¿åº¦ä¸ä¸€è‡´: {lengths}")
            # ç»Ÿä¸€é•¿åº¦ä¸ºæœ€å°å€¼
            min_length = min(lengths.values())
            predictions = {region: arr[:min_length] for region, arr in predictions.items()}
            prediction_intervals = {
                region: {
                    'lower': intervals['lower'][:min_length],
                    'upper': intervals['upper'][:min_length]
                }
                for region, intervals in prediction_intervals.items()
            }

        predictions_df = pd.DataFrame(predictions)
        self.prediction_intervals = prediction_intervals

        return predictions_df

    def evaluate(self, test_df: pd.DataFrame,
                predictions_df: pd.DataFrame,
                time_col: str) -> pd.DataFrame:
        """
        è¯„ä¼°é¢„æµ‹ç»“æœ
        """
        value_cols = [col for col in test_df.columns if col != time_col]

        print(f"\nè°ƒè¯•ä¿¡æ¯:")
        print(f"æµ‹è¯•é›†åˆ—: {test_df.columns.tolist()}")
        print(f"é¢„æµ‹é›†åˆ—: {predictions_df.columns.tolist()}")
        print(f"å¾…è¯„ä¼°çš„åŒºåŸŸåˆ—: {value_cols}")
        print(f"æµ‹è¯•é›†é•¿åº¦: {len(test_df)}")
        print(f"é¢„æµ‹é›†é•¿åº¦: {len(predictions_df)}")

        metrics = []
        failed_regions = []
        for region in value_cols:
            if region in predictions_df.columns:
                # ç¡®ä¿é•¿åº¦ä¸€è‡´ï¼šå–ä¸¤è€…ä¸­çš„è¾ƒå°å€¼
                min_len = min(len(test_df), len(predictions_df))
                y_true = test_df[region].values[:min_len]
                y_pred = predictions_df[region].values[:min_len]

                # è¿‡æ»¤NaN
                mask = ~(np.isnan(y_true) | np.isnan(y_pred))

                # æ£€æŸ¥é¢„æµ‹æ˜¯å¦å…¨éƒ¨å¤±è´¥
                if np.isnan(y_pred).all():
                    failed_regions.append(region)
                    continue

                if mask.sum() > 0:
                    y_true_clean = y_true[mask]
                    y_pred_clean = y_pred[mask]

                    mae = mean_absolute_error(y_true_clean, y_pred_clean)
                    rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))
                    mape = mean_absolute_percentage_error(y_true_clean, y_pred_clean) * 100

                    # è®¡ç®—è¦†ç›–ç‡ï¼ˆçœŸå®å€¼åœ¨é¢„æµ‹åŒºé—´å†…çš„æ¯”ä¾‹ï¼‰
                    if region in self.prediction_intervals:
                        lower = self.prediction_intervals[region]['lower'][:min_len]
                        upper = self.prediction_intervals[region]['upper'][:min_len]
                        # åªåœ¨æœ‰æ•ˆæ•°æ®ç‚¹ä¸Šè®¡ç®—è¦†ç›–ç‡
                        coverage = ((y_true[mask] >= lower[mask]) & (y_true[mask] <= upper[mask])).mean() * 100
                    else:
                        coverage = np.nan

                    metrics.append({
                        'region': region,
                        'test_mae': mae,
                        'test_rmse': rmse,
                        'test_mape': mape,
                        'coverage_80': coverage
                    })

        metrics_df = pd.DataFrame(metrics)

        print("\n" + "=" * 60)
        print("æµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
        print("=" * 60)

        if len(failed_regions) > 0:
            print(f"\n[WARN] ä»¥ä¸‹ {len(failed_regions)} ä¸ªåŒºåŸŸé¢„æµ‹å¤±è´¥:")
            for region in failed_regions:
                print(f"   - {region}")

        if len(metrics_df) == 0:
            print("\nè­¦å‘Š: æ‰€æœ‰åŒºåŸŸé¢„æµ‹éƒ½å¤±è´¥äº†ï¼Œæ²¡æœ‰å¯è¯„ä¼°çš„æ•°æ®")
            return metrics_df

        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        if 'test_mae' in metrics_df.columns:
            print(f"å¹³å‡MAE: {metrics_df['test_mae'].mean():.2f}")
        if 'test_rmse' in metrics_df.columns:
            print(f"å¹³å‡RMSE: {metrics_df['test_rmse'].mean():.2f}")
        if 'test_mape' in metrics_df.columns:
            print(f"å¹³å‡MAPE: {metrics_df['test_mape'].mean():.2f}%")
        if 'coverage_80' in metrics_df.columns:
            print(f"80%ç½®ä¿¡åŒºé—´è¦†ç›–ç‡: {metrics_df['coverage_80'].mean():.2f}%")

        return metrics_df

    def visualize_predictions(self, train_df: pd.DataFrame,
                             test_df: pd.DataFrame,
                             predictions_df: pd.DataFrame,
                             time_col: str,
                             region_names: Optional[List[str]] = None,
                             n_regions: int = 3,
                             show_intervals: bool = True,
                             save_path: Optional[str] = None):
        """
        å¯è§†åŒ–é¢„æµ‹ç»“æœï¼ˆåŒ…å«ç½®ä¿¡åŒºé—´ï¼‰
        """
        value_cols = [col for col in train_df.columns if col != time_col]

        if region_names is None:
            region_names = np.random.choice(value_cols, min(n_regions, len(value_cols)), replace=False)

        n_plots = len(region_names)
        fig, axes = plt.subplots(n_plots, 1, figsize=(15, 5*n_plots))
        if n_plots == 1:
            axes = [axes]

        for idx, region in enumerate(region_names):
            ax = axes[idx]

            # è®­ç»ƒæ•°æ®ï¼ˆæœ€åä¸€å‘¨ï¼‰
            train_series = train_df[region].iloc[-1008:]
            train_time = np.arange(len(train_series))

            # æµ‹è¯•æ•°æ® - æˆªå–åˆ°é¢„æµ‹é•¿åº¦
            min_len = min(len(test_df), len(predictions_df))
            test_series = test_df[region].iloc[:min_len]
            test_time = np.arange(len(train_series), len(train_series) + len(test_series))

            # é¢„æµ‹æ•°æ® - æˆªå–åˆ°ç›¸åŒé•¿åº¦
            pred_series = predictions_df[region].values[:min_len]
            pred_time = test_time[:len(pred_series)]

            # ç»˜åˆ¶åŸºæœ¬æ›²çº¿
            ax.plot(train_time, train_series.values, label='è®­ç»ƒæ•°æ®', color='blue', alpha=0.7)
            ax.plot(test_time, test_series.values, label='çœŸå®å€¼', color='green', linewidth=2)
            ax.plot(pred_time, pred_series, label='é¢„æµ‹å€¼ (ä¸­ä½æ•°)', color='red', linestyle='--', linewidth=2)

            # ç»˜åˆ¶ç½®ä¿¡åŒºé—´
            if show_intervals and region in self.prediction_intervals:
                lower = self.prediction_intervals[region]['lower'][:min_len]
                upper = self.prediction_intervals[region]['upper'][:min_len]

                ax.fill_between(
                    pred_time,
                    lower,
                    upper,
                    color='red',
                    alpha=0.2,
                    label='80% ç½®ä¿¡åŒºé—´'
                )

            ax.set_title(f'åŒºåŸŸ: {region}', fontsize=12, fontweight='bold')
            ax.set_xlabel('æ—¶é—´æ­¥ (10åˆ†é’Ÿé—´éš”)', fontsize=10)
            ax.set_ylabel('äº¤é€šæµé‡', fontsize=10)
            ax.legend(loc='best')
            ax.grid(True, alpha=0.3)
            ax.axvline(x=len(train_series), color='black', linestyle=':', linewidth=1, alpha=0.5)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"\nå¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")

        plt.close()

    def visualize_probabilistic_forecast(self, context: np.ndarray,
                                         true_future: Optional[np.ndarray] = None,
                                         region_name: str = "Unknown",
                                         save_path: Optional[str] = None):
        """
        å¯è§†åŒ–å•ä¸ªåŒºåŸŸçš„æ¦‚ç‡é¢„æµ‹ï¼ˆæ‰‡å½¢å›¾ï¼‰
        """
        # é¢„æµ‹
        result = self.predict_single_series(context)

        fig, ax = plt.subplots(figsize=(15, 6))

        # ç¡®ä¿æ‰€æœ‰é¢„æµ‹ç»“æœéƒ½æ˜¯ä¸€ç»´æ•°ç»„
        median = np.array(result['median']).flatten()
        q10 = np.array(result['q10']).flatten()
        q90 = np.array(result['q90']).flatten()
        q25 = np.array(result['q25']).flatten()
        q75 = np.array(result['q75']).flatten()

        # æ—¶é—´è½´
        context_time = np.arange(len(context))
        forecast_time = np.arange(len(context), len(context) + len(median))

        # ç»˜åˆ¶å†å²æ•°æ®
        ax.plot(context_time, context, label='å†å²æ•°æ®', color='blue', linewidth=2)

        # ç»˜åˆ¶é¢„æµ‹ä¸­ä½æ•°
        ax.plot(forecast_time, median, label='é¢„æµ‹ä¸­ä½æ•°', color='red', linewidth=2)

        # ç»˜åˆ¶ç½®ä¿¡åŒºé—´ï¼ˆæ‰‡å½¢ï¼‰
        ax.fill_between(forecast_time, q10, q90,
                       alpha=0.3, color='red', label='10-90%åˆ†ä½æ•°')
        ax.fill_between(forecast_time, q25, q75,
                       alpha=0.5, color='red', label='25-75%åˆ†ä½æ•°')

        # ç»˜åˆ¶çœŸå®å€¼ï¼ˆå¦‚æœæä¾›ï¼‰
        if true_future is not None:
            true_future_flat = np.array(true_future).flatten()
            true_time = forecast_time[:len(true_future_flat)]
            ax.plot(true_time, true_future_flat, label='çœŸå®å€¼', color='green',
                   linewidth=2, linestyle='--')

        ax.set_title(f'åŒºåŸŸ {region_name} çš„æ¦‚ç‡é¢„æµ‹', fontsize=14, fontweight='bold')
        ax.set_xlabel('æ—¶é—´æ­¥', fontsize=12)
        ax.set_ylabel('äº¤é€šæµé‡', fontsize=12)
        ax.legend(loc='best')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=len(context), color='black', linestyle=':', linewidth=1, alpha=0.5)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"\næ¦‚ç‡é¢„æµ‹å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")

        plt.close()


def main():
    """
    ä¸»å‡½æ•° - å®Œæ•´é¢„æµ‹æµç¨‹
    """
    print("=" * 60)
    print("Chronos-T5 é¢„è®­ç»ƒæ—¶é—´åºåˆ—æ¨¡å‹")
    print("=" * 60)

    if not CHRONOS_AVAILABLE:
        print("\né”™è¯¯: Chronosåº“æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install git+https://github.com/amazon-science/chronos-forecasting.git")
        return

    print("\n1. åŠ è½½æ•°æ®...")
    script_dir = os.path.dirname(os.path.abspath(__file__))
    try:
        from utils.config_loader import load_training_config
        cfg = load_training_config()
        data_path = cfg.get('dataset_path')
        if data_path is None or not os.path.exists(data_path):
            data_path = os.path.join(script_dir, '..', 'dataset', 'milano_traffic_nid.csv')
    except Exception:
        data_path = os.path.join(script_dir, '..', 'dataset', 'milano_traffic_nid.csv')
    print(f"[INFO] æ•°æ®è·¯å¾„: {data_path}")
    df = pd.read_csv(data_path)
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")

    tp = cfg.get('train_params_by_model', {}).get('Chronos', cfg.get('train_params', {})) if 'cfg' in locals() else {}
    split_ratio = float(tp.get('train_ratio', 0.9))
    split_idx = int(len(df) * split_ratio)
    train_df = df.iloc[:split_idx].reset_index(drop=True)
    test_df = df.iloc[split_idx:].reset_index(drop=True)

    # é€‰æ‹©éƒ¨åˆ†åŒºåŸŸ
    time_col = df.columns[0]
    all_regions = [col for col in df.columns if col != time_col]
    sample_regions = all_regions[:5]

    train_sample = train_df[[time_col] + sample_regions]
    test_sample = test_df[[time_col] + sample_regions]

    # 3. åˆ›å»ºé¢„æµ‹å™¨
    print("\n2. åˆ›å»º Chronos é¢„æµ‹å™¨...")
    mp = cfg.get('model_params_by_model', {}).get('Chronos', cfg.get('model_params', {})) if 'cfg' in locals() else {}
    prediction_length = int(tp.get('prediction_length', 288))
    num_samples = int(mp.get('num_samples', 20))
    size_map = {
        'tiny': 'amazon/chronos-t5-tiny',
        'mini': 'amazon/chronos-t5-mini',
        'small': 'amazon/chronos-t5-small',
        'base': 'amazon/chronos-t5-base',
        'large': 'amazon/chronos-t5-large'
    }
    model_size = str(mp.get('model_size', 'small')).lower()
    model_name = size_map.get(model_size, 'amazon/chronos-t5-small')
    temperature = float(mp.get('temperature', 1.0))
    forecaster = ChronosForecaster(
        model_name=model_name,
        prediction_length=prediction_length,
        num_samples=num_samples,
        temperature=temperature,
        device='auto'
    )

    # åˆ›å»ºoutputç›®å½•ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
    output_dir = os.path.join(script_dir, '..', 'output')
    output_dir = os.path.abspath(output_dir)  # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    os.makedirs(output_dir, exist_ok=True)
    print(f"\nè¾“å‡ºç›®å½•: {output_dir}")

    # 4. é¢„æµ‹
    print("\n3. è¿›è¡Œé¢„æµ‹...")
    context_length = int(tp.get('context_length', 2016))
    use_median = bool(mp.get('use_median', True))
    predictions = forecaster.predict(
        train_sample,
        time_col,
        sample_regions,
        context_length=context_length,
        prediction_length=prediction_length,
        use_median=use_median
    )

    # ä¿å­˜é¢„æµ‹ç»“æœ
    predictions.to_csv(os.path.join(output_dir, 'chronos_predictions.csv'), index=False)
    print("\né¢„æµ‹ç»“æœå·²ä¿å­˜")

    # 5. è¯„ä¼°
    print("\n4. è¯„ä¼°é¢„æµ‹ç»“æœ...")
    test_metrics = forecaster.evaluate(test_sample, predictions, time_col)
    test_metrics.to_csv(os.path.join(output_dir, 'chronos_test_metrics.csv'), index=False)

    # 6. å¯è§†åŒ–ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
    print("\n5. ç”Ÿæˆå¯è§†åŒ–...")
    forecaster.visualize_predictions(
        train_sample,
        test_sample,
        predictions,
        time_col,
        region_names=sample_regions[:3],
        show_intervals=True,
        save_path=os.path.join(output_dir, 'chronos_predictions_plot.png')
    )

    # 7. å•ä¸ªåŒºåŸŸçš„æ¦‚ç‡é¢„æµ‹å¯è§†åŒ–
    print("\n6. ç”Ÿæˆæ¦‚ç‡é¢„æµ‹æ‰‡å½¢å›¾...")
    sample_region = sample_regions[0]
    context = train_sample[sample_region].values[-2016:]  # 2å‘¨å†å²
    true_future = test_sample[sample_region].values[:288]  # 2å¤©çœŸå®å€¼

    forecaster.visualize_probabilistic_forecast(
        context,
        true_future,
        region_name=sample_region,
        save_path=os.path.join(output_dir, 'chronos_probabilistic_plot.png')
    )

    print("\n" + "=" * 60)
    print("[OK] Chronosæ¨¡å‹é¢„æµ‹å®Œæˆï¼")
    print("=" * 60)
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶ (ä¿å­˜åœ¨ {output_dir} ç›®å½•):")
    print("  - chronos_predictions.csv: é¢„æµ‹ç»“æœ")
    print("  - chronos_test_metrics.csv: æµ‹è¯•æŒ‡æ ‡")
    print("  - chronos_predictions_plot.png: é¢„æµ‹å¯è§†åŒ–ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰")
    print("  - chronos_probabilistic_plot.png: æ¦‚ç‡é¢„æµ‹æ‰‡å½¢å›¾")
    print("\næ³¨æ„:")
    print("  - Chronosæ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ— éœ€è®­ç»ƒå³å¯ä½¿ç”¨")
    print("  - æä¾›æ¦‚ç‡é¢„æµ‹å’Œç½®ä¿¡åŒºé—´")
    print("  - é€‚åˆé›¶æ ·æœ¬/å°‘æ ·æœ¬åœºæ™¯")


if __name__ == "__main__":
    main()
