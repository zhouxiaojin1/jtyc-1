"""
ç»“æœåˆ†æé¡µé¢
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å­—ä½“é…ç½®
from utils.plot_config import setup_chinese_font, apply_plot_style

# é…ç½®ä¸­æ–‡å­—ä½“
setup_chinese_font()


def show():
    """æ˜¾ç¤ºç»“æœåˆ†æé¡µé¢"""
    st.title("ç»“æœåˆ†æ")

    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
    output_path = Path("output")
    if not output_path.exists():
        st.warning("è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return

    # æŸ¥æ‰¾é¢„æµ‹ç»“æœæ–‡ä»¶ï¼ˆæ’é™¤ TBATSï¼‰
    prediction_files = [
        f for f in output_path.glob("*_predictions.csv")
        if "tbats" not in f.name.lower() and "lstm" not in f.name.lower() and "randomforest" not in f.name.lower()
    ]
    metrics_files = [
        f for f in output_path.glob("*_test_metrics.csv")
        if "tbats" not in f.name.lower() and "lstm" not in f.name.lower() and "randomforest" not in f.name.lower()
    ]

    if not prediction_files:
        st.info("æš‚æ— æ¨¡å‹é¢„æµ‹ç»“æœï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return

    # åˆ›å»ºé€‰é¡¹å¡
    tab1, tab2, tab3 = st.tabs(["é¢„æµ‹ç»“æœ", "æ¨¡å‹å¯¹æ¯”", "è¯¦ç»†åˆ†æ"])

    with tab1:
        show_prediction_results(prediction_files, metrics_files, output_path)

    with tab2:
        show_model_comparison(metrics_files, output_path)

    with tab3:
        show_detailed_analysis(prediction_files, metrics_files, output_path)


def show_prediction_results(prediction_files, metrics_files, output_path):
    """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
    st.markdown("### é¢„æµ‹ç»“æœ")

    # é€‰æ‹©æ¨¡å‹
    model_names = [f.stem.replace("_predictions", "") for f in prediction_files]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", model_names)

    # å±•ç¤ºå½“å‰æ¨¡å‹å¯¹åº”çš„æ•°æ®é›†ä¸è®­ç»ƒå‚æ•°æç¤º
    cfg_path = Path("config/training_config.json")
    if cfg_path.exists():
        try:
            import json
            with open(cfg_path, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
            history = cfg.get('history', {})
            ds_by_model = history.get('dataset_path_by_model', {})
            ds_path = ds_by_model.get(selected_model, cfg.get('dataset_path'))
            tp_by_model = history.get('train_params_by_model', {})
            tp = tp_by_model.get(selected_model, cfg.get('train_params', {}))
            pr = tp.get('prediction_length')
            tr = tp.get('train_ratio')
            cl = tp.get('context_length')
            info_text = f"æ•°æ®é›†ï¼š{Path(ds_path).name if ds_path else 'æœªé…ç½®'} | è®­ç»ƒæ¯”ä¾‹ï¼š{tr if tr is not None else 0.9} | å†å²çª—å£ï¼š{cl if cl is not None else 'é»˜è®¤'} | é¢„æµ‹æ­¥æ•°ï¼š{pr if pr is not None else 'é»˜è®¤'}"
            st.info(info_text)
        except Exception:
            pass

    # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶
    pred_file = output_path / f"{selected_model}_predictions.csv"
    metrics_file = output_path / f"{selected_model}_test_metrics.csv"

    if not pred_file.exists():
        st.error(f"âŒ æ‰¾ä¸åˆ°é¢„æµ‹æ–‡ä»¶ï¼š{pred_file}")
        return

    # åŠ è½½é¢„æµ‹ç»“æœ
    try:
        predictions = pd.read_csv(pred_file)

        st.markdown("#### é¢„æµ‹æ•°æ®")
        st.dataframe(predictions.head(100), use_container_width=True, height=300)

        # åŸºæœ¬ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("é¢„æµ‹æ­¥æ•°", len(predictions))

        with col2:
            st.metric("åŒºåŸŸæ•°é‡", len(predictions.columns))

        with col3:
            mean_pred = predictions.mean().mean()
            st.metric("å¹³å‡é¢„æµ‹å€¼", f"{mean_pred:.2f}")

        with col4:
            std_pred = predictions.std().mean()
            st.metric("å¹³å‡æ ‡å‡†å·®", f"{std_pred:.2f}")

        # åŠ è½½è¯„ä¼°æŒ‡æ ‡
        if metrics_file.exists():
            st.markdown("---")
            st.markdown("#### è¯„ä¼°æŒ‡æ ‡")

            metrics = pd.read_csv(metrics_file)

            # æ˜¾ç¤ºæŒ‡æ ‡è¡¨æ ¼
            st.dataframe(metrics, use_container_width=True)

            # æŒ‡æ ‡æ‘˜è¦
            if len(metrics) > 0:
                col1, col2, col3 = st.columns(3)

                with col1:
                    if 'test_mae' in metrics.columns:
                        avg_mae = metrics['test_mae'].mean()
                        st.metric("å¹³å‡ MAE", f"{avg_mae:.2f}")

                with col2:
                    if 'test_rmse' in metrics.columns:
                        avg_rmse = metrics['test_rmse'].mean()
                        st.metric("å¹³å‡ RMSE", f"{avg_rmse:.2f}")

                with col3:
                    if 'test_mape' in metrics.columns:
                        avg_mape = metrics['test_mape'].mean()
                        st.metric("å¹³å‡ MAPE", f"{avg_mape:.2f}%")

                # å¯è§†åŒ–æŒ‡æ ‡åˆ†å¸ƒ
                st.markdown("#### æŒ‡æ ‡åˆ†å¸ƒ")

                metric_cols = [c for c in metrics.columns if c != 'region']

                if len(metric_cols) > 0:
                    selected_metric = st.selectbox("é€‰æ‹©æŒ‡æ ‡", metric_cols)

                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.hist(metrics[selected_metric].dropna(), bins=30, edgecolor='black', alpha=0.7, color='#1f77b4')
                    apply_plot_style(ax,
                                   title=f'{selected_metric} åˆ†å¸ƒ',
                                   xlabel=selected_metric,
                                   ylabel='é¢‘æ•°',
                                   grid=True,
                                   legend=False)
                    st.pyplot(fig)
                    plt.close()

        # å¯è§†åŒ–é¢„æµ‹ç»“æœ
        st.markdown("---")
        st.markdown("#### é¢„æµ‹å¯è§†åŒ–")

        is_pair_format = 'y_pred' in predictions.columns and 'y_true' in predictions.columns

        # å¦‚æœæ˜¯y_true/y_predæ ¼å¼ï¼ˆLSTMç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼‰
        if is_pair_format:
            st.info("æ£€æµ‹åˆ°æ·±åº¦å­¦ä¹ æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼ˆy_true vs y_predï¼‰")

            # ç»˜åˆ¶é¢„æµ‹å€¼vsçœŸå®å€¼å¯¹æ¯”å›¾
            fig, axes = plt.subplots(2, 1, figsize=(14, 10))

            # ç¬¬ä¸€å¼ å›¾ï¼šé¢„æµ‹å€¼å’ŒçœŸå®å€¼å¯¹æ¯”ï¼ˆæŠ˜çº¿å›¾ï¼‰
            ax = axes[0]
            time_steps = np.arange(len(predictions))

            ax.plot(time_steps, predictions['y_true'].values,
                   linewidth=2, label='çœŸå®å€¼', color='#2ca02c', alpha=0.9)
            ax.plot(time_steps, predictions['y_pred'].values,
                   linewidth=2, label='é¢„æµ‹å€¼', color='#d62728', linestyle='--', alpha=0.9)

            # è®¡ç®—è¯¯å·®
            mae = np.mean(np.abs(predictions['y_true'].values - predictions['y_pred'].values))
            rmse = np.sqrt(np.mean((predictions['y_true'].values - predictions['y_pred'].values)**2))

            ax.text(0.02, 0.98, f'MAE: {mae:.4f}\nRMSE: {rmse:.4f}',
                   transform=ax.transAxes, fontsize=11,
                   verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

            apply_plot_style(ax,
                           title='é¢„æµ‹å€¼ vs çœŸå®å€¼å¯¹æ¯”',
                           xlabel='æ—¶é—´æ­¥',
                           ylabel='æ ‡å‡†åŒ–åçš„å€¼',
                           grid=True,
                           legend=True)

            # ç¬¬äºŒå¼ å›¾ï¼šè¯¯å·®åˆ†å¸ƒå›¾
            ax = axes[1]
            errors = predictions['y_pred'].values - predictions['y_true'].values

            ax.plot(time_steps, errors, linewidth=1.5, color='#ff7f0e', alpha=0.7, label='é¢„æµ‹è¯¯å·®')
            ax.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)
            ax.fill_between(time_steps, 0, errors, alpha=0.3, color='#ff7f0e')

            apply_plot_style(ax,
                           title='é¢„æµ‹è¯¯å·®éšæ—¶é—´å˜åŒ–',
                           xlabel='æ—¶é—´æ­¥',
                           ylabel='è¯¯å·® (é¢„æµ‹å€¼ - çœŸå®å€¼)',
                           grid=True,
                           legend=True)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

            # æ·»åŠ æ•£ç‚¹å›¾å¯¹æ¯”
            st.markdown("##### æ•£ç‚¹å›¾åˆ†æ")
            fig, ax = plt.subplots(figsize=(8, 8))

            ax.scatter(predictions['y_true'].values, predictions['y_pred'].values,
                      alpha=0.5, s=20, color='#1f77b4')

            # æ·»åŠ ç†æƒ³é¢„æµ‹çº¿ï¼ˆy=xï¼‰
            min_val = min(predictions['y_true'].min(), predictions['y_pred'].min())
            max_val = max(predictions['y_true'].max(), predictions['y_pred'].max())
            ax.plot([min_val, max_val], [min_val, max_val],
                   'r--', linewidth=2, label='ç†æƒ³é¢„æµ‹çº¿ (y=x)')

            # è®¡ç®—ç›¸å…³ç³»æ•°
            corr = np.corrcoef(predictions['y_true'].values, predictions['y_pred'].values)[0, 1]
            ax.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr:.4f}',
                   transform=ax.transAxes, fontsize=12,
                   verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

            apply_plot_style(ax,
                           title='çœŸå®å€¼ vs é¢„æµ‹å€¼æ•£ç‚¹å›¾',
                           xlabel='çœŸå®å€¼',
                           ylabel='é¢„æµ‹å€¼',
                           grid=True,
                           legend=True)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.markdown("##### é¢„æµ‹ç»Ÿè®¡")
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("å¹³å‡ç»å¯¹è¯¯å·® (MAE)", f"{mae:.4f}")

            with col2:
                st.metric("å‡æ–¹æ ¹è¯¯å·® (RMSE)", f"{rmse:.4f}")

            with col3:
                st.metric("ç›¸å…³ç³»æ•°", f"{corr:.4f}")

            with col4:
                mape = np.mean(np.abs((predictions['y_true'].values - predictions['y_pred'].values) /
                                     (predictions['y_true'].values + 1e-8))) * 100
                st.metric("å¹³å‡ç™¾åˆ†æ¯”è¯¯å·® (MAPE)", f"{mape:.2f}%")

            return  # å¯¹äºpairæ ¼å¼ï¼Œåˆ°è¿™é‡Œå°±ç»“æŸ

        # ä»¥ä¸‹æ˜¯åŸæ¥çš„å¤šåŒºåŸŸæ ¼å¼å¤„ç†
        # åŠ è½½åŸå§‹æ•°æ®ä»¥è·å–å†å²å€¼å’ŒçœŸå®å€¼
        # ä¼˜å…ˆä½¿ç”¨è®­ç»ƒé…ç½®ä¸­çš„æ•°æ®é›†è·¯å¾„
        cfg_path = Path("config/training_config.json")
        data_path = None
        train_ratio = 0.9
        if cfg_path.exists():
            try:
                import json
                with open(cfg_path, 'r', encoding='utf-8') as f:
                    cfg = json.load(f)
                history = cfg.get('history', {})
                ds_by_model = history.get('dataset_path_by_model', {})
                dp_global = cfg.get('dataset_path')
                dp = ds_by_model.get(selected_model, dp_global)
                if dp:
                    data_path = Path(dp)
                tp_by_model = history.get('train_params_by_model', {})
                trp = tp_by_model.get(selected_model, cfg.get('train_params', {})).get('train_ratio')
                if isinstance(trp, (int, float)):
                    train_ratio = float(trp)
            except Exception:
                pass
        if data_path is None or not data_path.exists():
            data_path = Path("dataset/milano_traffic_nid.csv")
            if not data_path.exists():
                data_path = Path("dataset/trentino_traffic_nid.csv")

        has_comparison_data = False
        train_df = None
        test_df = None

        if data_path.exists():
            try:
                # åŠ è½½å®Œæ•´æ•°æ®
                full_data = pd.read_csv(data_path)

                # ä½¿ç”¨é…ç½®ä¸­çš„è®­ç»ƒæ¯”ä¾‹ï¼ˆé»˜è®¤0.9ï¼‰
                split_idx = int(len(full_data) * train_ratio)
                train_df = full_data.iloc[:split_idx]
                test_df = full_data.iloc[split_idx:split_idx + len(predictions)]

                # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—
                time_col = full_data.columns[0]
                has_comparison_data = True

            except Exception as e:
                st.warning(f"æ— æ³•åŠ è½½åŸå§‹æ•°æ®è¿›è¡Œå¯¹æ¯”: {str(e)}")

        # é€‰æ‹©åŒºåŸŸ
        regions = predictions.columns.tolist()
        selected_regions = st.multiselect(
            "é€‰æ‹©è¦å¯è§†åŒ–çš„åŒºåŸŸï¼ˆæœ€å¤š5ä¸ªï¼‰",
            regions,
            default=(regions[:3] if len(regions) >= 3 else regions)
        )

        if len(selected_regions) > 5:
            st.warning("âš ï¸ æœ€å¤šé€‰æ‹©5ä¸ªåŒºåŸŸ")
            selected_regions = selected_regions[:5]

        if selected_regions:
            if has_comparison_data and train_df is not None and test_df is not None:
                # ç»˜åˆ¶å®Œæ•´çš„å¯¹æ¯”å›¾ï¼šè®­ç»ƒæ•°æ® + çœŸå®å€¼ + é¢„æµ‹å€¼
                fig, axes = plt.subplots(len(selected_regions), 1,
                                        figsize=(14, 5*len(selected_regions)))

                if len(selected_regions) == 1:
                    axes = [axes]

                for idx, region in enumerate(selected_regions):
                    ax = axes[idx]

                    # è·å–é¢„æµ‹æ•°æ®é•¿åº¦
                    pred_len = len(predictions)

                    # è·å–è®­ç»ƒæ•°æ®ï¼ˆæ˜¾ç¤ºæœ€å1008ä¸ªç‚¹ï¼Œçº¦7å¤©ï¼‰
                    train_window = min(1008, len(train_df))
                    train_data = train_df[region].iloc[-train_window:].values
                    train_time = np.arange(len(train_data))

                    # è·å–æµ‹è¯•æ•°æ®ï¼ˆçœŸå®å€¼ï¼‰ï¼Œé•¿åº¦ä¸é¢„æµ‹æ•°æ®åŒ¹é…
                    test_data_available = min(pred_len, len(test_df))
                    test_data = test_df[region].values[:test_data_available]

                    # è·å–é¢„æµ‹æ•°æ®ï¼ˆå¯èƒ½éœ€è¦æˆªæ–­ï¼‰
                    pred_data = predictions[region].values[:test_data_available]

                    # è®¡ç®—æ—¶é—´è½´ï¼ˆç¡®ä¿é•¿åº¦ä¸€è‡´ï¼‰
                    test_time = np.arange(len(train_data), len(train_data) + test_data_available)
                    pred_time = test_time[:len(pred_data)]

                    # ç»˜åˆ¶è®­ç»ƒæ•°æ®ï¼ˆè“è‰²ï¼‰
                    ax.plot(train_time, train_data, linewidth=1.5,
                           label='è®­ç»ƒæ•°æ®', color='#1f77b4', alpha=0.8)

                    # ç»˜åˆ¶çœŸå®å€¼ï¼ˆç»¿è‰²ï¼‰ - åªç»˜åˆ¶ä¸é¢„æµ‹é•¿åº¦ç›¸åŒçš„éƒ¨åˆ†
                    if len(test_data) > 0:
                        ax.plot(test_time[:len(test_data)], test_data, linewidth=2,
                               label='çœŸå®å€¼', color='#2ca02c', alpha=0.9)

                    # ç»˜åˆ¶é¢„æµ‹å€¼ï¼ˆçº¢è‰²è™šçº¿ï¼‰
                    ax.plot(pred_time, pred_data, linewidth=2,
                           label='é¢„æµ‹å€¼', color='#d62728', linestyle='--', alpha=0.9)

                    # ç»˜åˆ¶åˆ†ç•Œçº¿
                    ax.axvline(x=len(train_data), color='gray',
                              linestyle=':', linewidth=1.5, alpha=0.7)

                    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
                    apply_plot_style(ax,
                                   title=f'åŒºåŸŸ: {region}',
                                   xlabel='æ—¶é—´æ­¥ (10åˆ†é’Ÿé—´éš”)',
                                   ylabel='äº¤é€šæµé‡',
                                   grid=True,
                                   legend=True)

                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

            else:
                # ä»…ç»˜åˆ¶é¢„æµ‹æ›²çº¿ï¼ˆæ— å†å²æ•°æ®å¯¹æ¯”ï¼‰
                fig, axes = plt.subplots(len(selected_regions), 1,
                                        figsize=(12, 4*len(selected_regions)))

                if len(selected_regions) == 1:
                    axes = [axes]

                for idx, region in enumerate(selected_regions):
                    ax = axes[idx]
                    ax.plot(predictions[region].values, linewidth=2,
                           label='é¢„æµ‹å€¼', color='#d62728')

                    apply_plot_style(ax,
                                   title=f'åŒºåŸŸ: {region}',
                                   xlabel='æ—¶é—´æ­¥',
                                   ylabel='äº¤é€šæµé‡',
                                   grid=True,
                                   legend=True)

                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                st.info("æç¤ºï¼šæ”¾ç½®åŸå§‹æ•°æ®æ–‡ä»¶åˆ° dataset ç›®å½•å¯æŸ¥çœ‹å®Œæ•´çš„å†å²å€¼å’ŒçœŸå®å€¼å¯¹æ¯”")

    except Exception as e:
        st.error(f"åŠ è½½é¢„æµ‹ç»“æœå¤±è´¥ï¼š{str(e)}")


def show_model_comparison(metrics_files, output_path):
    """æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”"""
    st.markdown("### æ¨¡å‹å¯¹æ¯”")

    if len(metrics_files) < 2:
        st.info("éœ€è¦è‡³å°‘ 2 ä¸ªæ¨¡å‹æ‰èƒ½è¿›è¡Œå¯¹æ¯”")
        return

    # åŠ è½½æ‰€æœ‰æ¨¡å‹çš„æŒ‡æ ‡
    all_metrics = {}

    for metrics_file in metrics_files:
        model_name = metrics_file.stem.replace("_test_metrics", "")
        try:
            metrics = pd.read_csv(metrics_file)
            all_metrics[model_name] = metrics
        except Exception as e:
            st.warning(f"æ— æ³•åŠ è½½ {model_name} çš„æŒ‡æ ‡ï¼š{str(e)}")

    if len(all_metrics) == 0:
        st.error("æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹æŒ‡æ ‡")
        return

    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    st.markdown("#### å¹³å‡æ€§èƒ½å¯¹æ¯”")

    comparison_data = []

    for model_name, metrics in all_metrics.items():
        row = {'æ¨¡å‹': model_name}

        if 'test_mae' in metrics.columns:
            row['MAE'] = metrics['test_mae'].mean()

        if 'test_rmse' in metrics.columns:
            row['RMSE'] = metrics['test_rmse'].mean()

        if 'test_mape' in metrics.columns:
            row['MAPE (%)'] = metrics['test_mape'].mean()

        comparison_data.append(row)

    comparison_df = pd.DataFrame(comparison_data)

    # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
    st.dataframe(comparison_df, use_container_width=True)

    # å¯è§†åŒ–å¯¹æ¯”
    if len(comparison_df) > 0:
        st.markdown("#### æ€§èƒ½å¯¹æ¯”å›¾")

        # é€‰æ‹©æŒ‡æ ‡
        metric_cols = [c for c in comparison_df.columns if c != 'æ¨¡å‹']

        if len(metric_cols) > 0:
            selected_metric = st.selectbox("é€‰æ‹©å¯¹æ¯”æŒ‡æ ‡", metric_cols)

            # æŸ±çŠ¶å›¾
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.bar(comparison_df['æ¨¡å‹'], comparison_df[selected_metric], color='#1f77b4', alpha=0.7)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, v in enumerate(comparison_df[selected_metric]):
                ax.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=9)

            apply_plot_style(ax,
                           title=f'{selected_metric} å¯¹æ¯”',
                           xlabel='æ¨¡å‹',
                           ylabel=selected_metric,
                           grid=True,
                           legend=False)

            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

    # è¯¦ç»†å¯¹æ¯”
    with st.expander("è¯¦ç»†å¯¹æ¯”ï¼ˆæŒ‰åŒºåŸŸï¼‰"):
        # é€‰æ‹©æŒ‡æ ‡
        available_metrics = ['test_mae', 'test_rmse', 'test_mape']
        selected_metric = st.selectbox(
            "é€‰æ‹©æŒ‡æ ‡",
            available_metrics,
            key="detailed_metric"
        )

        # åˆå¹¶æ‰€æœ‰æ¨¡å‹çš„æ•°æ®
        merged_data = None

        for model_name, metrics in all_metrics.items():
            if selected_metric in metrics.columns and 'region' in metrics.columns:
                temp_df = metrics[['region', selected_metric]].copy()
                temp_df = temp_df.rename(columns={selected_metric: model_name})

                if merged_data is None:
                    merged_data = temp_df
                else:
                    merged_data = merged_data.merge(temp_df, on='region', how='outer')

        if merged_data is not None:
            st.dataframe(merged_data, use_container_width=True)

            # é€‰æ‹©åŒºåŸŸç»˜åˆ¶å¯¹æ¯”
            regions = merged_data['region'].tolist()
            selected_regions = st.multiselect(
                "é€‰æ‹©åŒºåŸŸæŸ¥çœ‹å¯¹æ¯”",
                regions,
                default=regions[:5] if len(regions) >= 5 else regions,
                key="comp_regions"
            )

            if selected_regions:
                filtered_data = merged_data[merged_data['region'].isin(selected_regions)]

                # ç»˜åˆ¶å¯¹æ¯”å›¾
                fig, ax = plt.subplots(figsize=(12, 6))

                x = np.arange(len(selected_regions))
                width = 0.8 / len(all_metrics)

                colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
                for idx, model_name in enumerate(all_metrics.keys()):
                    if model_name in filtered_data.columns:
                        offset = width * idx - width * len(all_metrics) / 2
                        color = colors[idx % len(colors)]
                        ax.bar(x + offset, filtered_data[model_name],
                              width, label=model_name, color=color, alpha=0.8)

                ax.set_xticks(x)
                ax.set_xticklabels(selected_regions, rotation=45, ha='right')

                apply_plot_style(ax,
                               title=f'{selected_metric} æŒ‰åŒºåŸŸå¯¹æ¯”',
                               xlabel='åŒºåŸŸ',
                               ylabel=selected_metric,
                               grid=True,
                               legend=True)

                plt.tight_layout()
                st.pyplot(fig)
                plt.close()


def show_detailed_analysis(prediction_files, metrics_files, output_path):
    """æ˜¾ç¤ºè¯¦ç»†åˆ†æ"""
    st.markdown("### è¯¦ç»†åˆ†æ")

    # é€‰æ‹©æ¨¡å‹
    model_names = [f.stem.replace("_predictions", "") for f in prediction_files]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹è¿›è¡Œè¯¦ç»†åˆ†æ", model_names, key="detailed_model")

    # åŠ è½½æ•°æ®
    pred_file = output_path / f"{selected_model}_predictions.csv"
    metrics_file = output_path / f"{selected_model}_test_metrics.csv"

    if not pred_file.exists():
        st.error(f"âŒ æ‰¾ä¸åˆ°é¢„æµ‹æ–‡ä»¶ï¼š{pred_file}")
        return

    try:
        predictions = pd.read_csv(pred_file)

        # é¢„æµ‹ç»Ÿè®¡åˆ†æ
        st.markdown("#### é¢„æµ‹ç»Ÿè®¡åˆ†æ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("##### é¢„æµ‹å€¼åˆ†å¸ƒ")

            fig, ax = plt.subplots(figsize=(10, 6))

            # æ‰€æœ‰åŒºåŸŸçš„é¢„æµ‹å€¼åˆ†å¸ƒ
            all_predictions = predictions.values.flatten()
            ax.hist(all_predictions, bins=50, edgecolor='black', alpha=0.7, color='#1f77b4')

            apply_plot_style(ax,
                           title='æ‰€æœ‰åŒºåŸŸé¢„æµ‹å€¼åˆ†å¸ƒ',
                           xlabel='é¢„æµ‹å€¼',
                           ylabel='é¢‘æ•°',
                           grid=True,
                           legend=False)

            st.pyplot(fig)
            plt.close()

        with col2:
            st.markdown("##### é¢„æµ‹è¶‹åŠ¿")

            # è®¡ç®—å¹³å‡é¢„æµ‹å€¼éšæ—¶é—´çš„å˜åŒ–
            avg_predictions = predictions.mean(axis=1)

            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(avg_predictions.values, linewidth=2, color='#1f77b4')

            apply_plot_style(ax,
                           title='å¹³å‡é¢„æµ‹å€¼è¶‹åŠ¿',
                           xlabel='æ—¶é—´æ­¥',
                           ylabel='å¹³å‡é¢„æµ‹å€¼',
                           grid=True,
                           legend=False)

            st.pyplot(fig)
            plt.close()

        # åŒºåŸŸåˆ†æ
        if metrics_file.exists():
            st.markdown("---")
            st.markdown("#### åŒºåŸŸæ€§èƒ½åˆ†æ")

            metrics = pd.read_csv(metrics_file)

            if 'region' in metrics.columns and 'test_mae' in metrics.columns:
                # æœ€å¥½å’Œæœ€å·®çš„åŒºåŸŸ
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("##### è¡¨ç°æœ€å¥½çš„åŒºåŸŸï¼ˆMAEï¼‰")

                    best_regions = metrics.nsmallest(5, 'test_mae')
                    st.dataframe(best_regions, use_container_width=True)

                with col2:
                    st.markdown("##### è¡¨ç°æœ€å·®çš„åŒºåŸŸï¼ˆMAEï¼‰")

                    worst_regions = metrics.nlargest(5, 'test_mae')
                    st.dataframe(worst_regions, use_container_width=True)

                # è¯¯å·®åˆ†å¸ƒ
                st.markdown("##### è¯¯å·®åˆ†å¸ƒåˆ†æ")

                fig, axes = plt.subplots(1, 3, figsize=(15, 5))

                colors = ['#1f77b4', '#ff7f0e', '#2ca02c']

                if 'test_mae' in metrics.columns:
                    axes[0].hist(metrics['test_mae'], bins=30, edgecolor='black', alpha=0.7, color=colors[0])
                    apply_plot_style(axes[0],
                                   title='MAE åˆ†å¸ƒ',
                                   xlabel='MAE',
                                   ylabel='é¢‘æ•°',
                                   grid=True,
                                   legend=False)

                if 'test_rmse' in metrics.columns:
                    axes[1].hist(metrics['test_rmse'], bins=30, edgecolor='black', alpha=0.7, color=colors[1])
                    apply_plot_style(axes[1],
                                   title='RMSE åˆ†å¸ƒ',
                                   xlabel='RMSE',
                                   ylabel='é¢‘æ•°',
                                   grid=True,
                                   legend=False)

                if 'test_mape' in metrics.columns:
                    axes[2].hist(metrics['test_mape'], bins=30, edgecolor='black', alpha=0.7, color=colors[2])
                    apply_plot_style(axes[2],
                                   title='MAPE åˆ†å¸ƒ',
                                   xlabel='MAPE (%)',
                                   ylabel='é¢‘æ•°',
                                   grid=True,
                                   legend=False)

                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

        # å¯¼å‡ºæŠ¥å‘Š
        st.markdown("---")
        st.markdown("#### å¯¼å‡ºåˆ†ææŠ¥å‘Š")

        if st.button("ç”ŸæˆæŠ¥å‘Š"):
            generate_report(selected_model, predictions, metrics if metrics_file.exists() else None)

    except Exception as e:
        st.error(f"åˆ†æå¤±è´¥ï¼š{str(e)}")


def generate_report(model_name, predictions, metrics):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report_lines = []

    report_lines.append(f"# {model_name} æ¨¡å‹åˆ†ææŠ¥å‘Š\n")
    report_lines.append(f"ç”Ÿæˆæ—¶é—´ï¼š{pd.Timestamp.now()}\n")
    report_lines.append("\n---\n")

    # åŸºæœ¬ä¿¡æ¯
    report_lines.append("## åŸºæœ¬ä¿¡æ¯\n")
    report_lines.append(f"- é¢„æµ‹æ­¥æ•°ï¼š{len(predictions)}\n")
    report_lines.append(f"- åŒºåŸŸæ•°é‡ï¼š{len(predictions.columns)}\n")
    report_lines.append(f"- å¹³å‡é¢„æµ‹å€¼ï¼š{predictions.mean().mean():.2f}\n")
    report_lines.append(f"- é¢„æµ‹å€¼æ ‡å‡†å·®ï¼š{predictions.std().mean():.2f}\n")
    report_lines.append("\n")

    # è¯„ä¼°æŒ‡æ ‡
    if metrics is not None:
        report_lines.append("## è¯„ä¼°æŒ‡æ ‡\n")

        if 'test_mae' in metrics.columns:
            report_lines.append(f"- å¹³å‡ MAEï¼š{metrics['test_mae'].mean():.2f}\n")

        if 'test_rmse' in metrics.columns:
            report_lines.append(f"- å¹³å‡ RMSEï¼š{metrics['test_rmse'].mean():.2f}\n")

        if 'test_mape' in metrics.columns:
            report_lines.append(f"- å¹³å‡ MAPEï¼š{metrics['test_mape'].mean():.2f}%\n")

        report_lines.append("\n")

        # æœ€å¥½å’Œæœ€å·®çš„åŒºåŸŸ
        if 'region' in metrics.columns and 'test_mae' in metrics.columns:
            report_lines.append("### è¡¨ç°æœ€å¥½çš„åŒºåŸŸï¼ˆTop 5ï¼‰\n")
            best = metrics.nsmallest(5, 'test_mae')
            for _, row in best.iterrows():
                report_lines.append(f"- {row['region']}: MAE = {row['test_mae']:.2f}\n")

            report_lines.append("\n### è¡¨ç°æœ€å·®çš„åŒºåŸŸï¼ˆBottom 5ï¼‰\n")
            worst = metrics.nlargest(5, 'test_mae')
            for _, row in worst.iterrows():
                report_lines.append(f"- {row['region']}: MAE = {row['test_mae']:.2f}\n")

    # ä¿å­˜æŠ¥å‘Š
    report_path = Path("output") / f"{model_name}_analysis_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.writelines(report_lines)

    st.success(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{report_path}")

    # æä¾›ä¸‹è½½
    with open(report_path, 'r', encoding='utf-8') as f:
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Š",
            data=f.read(),
            file_name=f"{model_name}_analysis_report.md",
            mime='text/markdown'
        )
